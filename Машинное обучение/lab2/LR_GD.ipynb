{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа № 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация градиентного спуска\n",
    "\n",
    "Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью:\n",
    "\n",
    "**Задание 1** Градиентного спуска;\n",
    "\n",
    "**Задание 2** Стохастического градиентного спуска.\n",
    "\n",
    "\n",
    "Во всех пунктах необходимо соблюдать следующие условия:\n",
    "\n",
    "* Все вычисления должны быть векторизованы;\n",
    "* Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
    "* В качестве критерия останова необходимо использовать (одновременно):\n",
    "\n",
    "    * проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, задаваемого параметром `tolerance`);\n",
    "    * достижение максимального числа итераций (например, 10000, задаваемого параметром `max_iter`).\n",
    "* Чтобы проследить, что оптимизационный процесс действительно сходится, будем использовать атрибут класса `loss_history` — в нём после вызова метода `fit` должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту);\n",
    "* Инициализировать веса можно случайным образом или нулевым вектором. \n",
    "\n",
    "\n",
    "Ниже приведён шаблон класса, который должен содержать код реализации каждого из методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формула градиента\n",
    "\n",
    "Функция потерь в векторном (матричном) виде можно представить следующим образом:\n",
    "\n",
    "$$Q(w) = \\frac{ 1 }{ n } \\|X w - y\\|^2$$\n",
    "\n",
    "\n",
    "Тогда производная этой функции будет принимать следующий вид (производная вычисляется как **производная сложной функции**):\n",
    "\n",
    "$$\\frac{ dQ }{ d w }= \\frac{ 1 }{ n } (\\|X w - y\\|^2)' * (X w - y)'  =  \\frac{ 1 }{ n } 2(X w -y)X = \\frac{ 1 }{ n } 2X(Xw-y)$$\n",
    "\n",
    "Но, т. к. здесь используются матрицы, то $X$ перед скобками необходимо транспонировать, чтобы было возможным осуществить операцию векторного умножения, нужно соблюсти правило:\n",
    "> Чтобы матрицу A можно было умножить на матрицу B нужно, чтобы число столбцов матрицы A равнялось числу строк матрицы B.\n",
    "\n",
    "Поэтому, производная функции потерь будет иметь следующий вид:\n",
    "\n",
    "$$\\frac{ dQ }{ d w }= \\frac{ 1 }{ n } 2X^{T}(Xw-y)$$\n",
    "\n",
    "Т. к. в выражении 1 переменная, то градиент будет выглядеть так:\n",
    "\n",
    "$$\\nabla Q(w) = \\frac{ 1 }{ n } 2X^{T}(Xw-y) $$\n",
    "\n",
    "Подробнее см. раздел 5.3  Линейная регрессия в [Математические методы обучения по прецедентам (теория обучения машин)](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinearReg(BaseEstimator):\n",
    "    def __init__(self, gd_type='stochastic', \n",
    "                 tolerance=1e-4, max_iter=1000, w0=None, alpha=0, eta=1e-5):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'stochastic'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) - init weights\n",
    "        eta: learning rate\n",
    "        \"\"\"\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.loss_history = None \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if self.w0 is not None:\n",
    "            self.w = self.w0.copy()\n",
    "        else:\n",
    "            self.w = np.random.normal(0, 0.01, n_features + 1)\n",
    "        \n",
    "        X_with_bias = np.c_[np.ones(n_samples), X]\n",
    "        w_prev = self.w.copy()\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            if self.gd_type == 'full':\n",
    "                gradient = self.calc_gradient(X_with_bias, y)\n",
    "                self.w = self.w - self.eta * gradient\n",
    "                \n",
    "            elif self.gd_type == 'stochastic':\n",
    "                random_idx = np.random.randint(n_samples)\n",
    "                X_single = X_with_bias[random_idx:random_idx+1]  # Сохраняем размерность\n",
    "                y_single = y[random_idx:random_idx+1]\n",
    "                gradient = self.calc_gradient(X_single, y_single)\n",
    "                self.w = self.w - self.eta * gradient\n",
    "            else:\n",
    "                raise Exception('Unknown gd_type')\n",
    "\n",
    "            current_loss = self.calc_loss(X_with_bias, y)\n",
    "            self.loss_history.append(current_loss)\n",
    "            \n",
    "            weight_change = np.linalg.norm(self.w - w_prev)\n",
    "            if weight_change < self.tolerance:\n",
    "                print(f\"Сходимость достигнута на итерации {iteration}\")\n",
    "                break\n",
    "            w_prev = self.w.copy()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        n_samples = X.shape[0]\n",
    "        X_with_bias = np.c_[np.ones(n_samples), X]\n",
    "        # Предсказание: y_pred = X * w\n",
    "        return X_with_bias @ self.w\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        y_pred = X @ self.w\n",
    "        errors = y_pred - y\n",
    "        # Градиент: (2/n) * X^T * (X*w - y)\n",
    "        gradient = (2.0 / n_samples) * (X.T @ errors) + 2 * self.alpha * self.w\n",
    "        return gradient\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        n_samples = X.shape[0]\n",
    "        # Вычисляем предсказания\n",
    "        y_pred = X @ self.w\n",
    "        # MSE: (1/n) * sum((y_pred - y)^2)\n",
    "        mse = np.mean((y_pred - y) ** 2)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**. \n",
    "* Загрузите данные из лабораторной работы № 3 ([train.csv](https://www.kaggle.com/c/nyc-taxi-trip-duration/data));\n",
    "* Разбейте выборку на обучающую и тестовую в отношении 7:3 с random_seed=0;\n",
    "* Преобразуйте целевую переменную `trip_duration` как $\\hat{y} = \\log{(y + 1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.96463</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937          -73.96463   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N            455  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "numerical_features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', \n",
    "                      'passenger_count']\n",
    "X = df[numerical_features]\n",
    "y = np.log1p(df['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4**. Обучите и провалидируйте модели на данных из предыдущего пункта, сравните качество между методами по метрикам MSE и $R^2$. Исследуйте влияние параметров `max_iter` и `eta` на процесс оптимизации. Согласуется ли оно с вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сходимость достигнута на итерации 920\n",
      "=== ОЦЕНКА КАЧЕСТВА МОДЕЛИ ===\n",
      "MAE: 0.61\n",
      "MSE: 0.63\n",
      "RMSE: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_error\n",
    "\n",
    "reg = LinearReg(gd_type='full', tolerance=1e-6, max_iter=1000, eta=1e-6, alpha=15)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"=== ОЦЕНКА КАЧЕСТВА МОДЕЛИ ===\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
