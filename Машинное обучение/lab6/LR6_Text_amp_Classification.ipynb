{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа - Работа с текстом\n",
    "\n",
    "Лабораторная работа посвящена работе с текстом и классификации. Мы будем классифицировать твиты о коронавирусе. Скачать данные из папки data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41157, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location    TweetAt  \\\n",
       "0      3799       48751     London 2020-03-16   \n",
       "1      3800       48752         UK 2020-03-16   \n",
       "2      3801       48753  Vagabonds 2020-03-16   \n",
       "3      3802       48754        NaN 2020-03-16   \n",
       "4      3803       48755        NaN 2020-03-16   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coronavirus_tweets_with_labels.csv', encoding='ISO-8859-1', parse_dates=['TweetAt'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.**\n",
    "\n",
    "Сделайте 3 группы в целевой переменной: `Extremely Positive` отметьте как `Positive`, а `Extremely Negative` – `Negative`. Сколько наблюдений в каждом классе? Закодируйте их в числовом виде простым LabelEncoding'ом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Positive    18046\n",
      "Negative    15398\n",
      "Neutral      7713\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Sentiment'] = df['Sentiment'].replace({'Extremely Positive': 'Positive', 'Extremely Negative': 'Negative'})\n",
    "\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.**\n",
    "\n",
    "Добавьте колонку с месяцем твита. Нарисуйте barchart, где по оси Х – месяц, по оси Y – количество твитов в этом месяце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Month'] = pd.to_datetime(df['TweetAt'], format='%Y-%m-%d').dt.month\n",
    "\n",
    "tweets_per_month = df['Month'].value_counts()\n",
    "plt.bar(tweets_per_month.index, tweets_per_month.values)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Tweets per Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.**\n",
    "\n",
    "Очистим твиты. Удалите ссылки, пунктуацию, теги, которые начинаются с @ и #."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                            and  and \n",
      "1    advice Talk to your neighbours family to excha...\n",
      "2    Coronavirus Australia Woolworths to give elder...\n",
      "3    My food stock is not the only one which is emp...\n",
      "4    Me ready to go at supermarket during the  outb...\n",
      "Name: CleanedTweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'@[\\w]+', '', tweet)  # Remove @tags\n",
    "    tweet = re.sub(r'#[\\w]+', '', tweet)  # Remove #tags\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)  # Remove links\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)  # Remove punctuation\n",
    "    return tweet\n",
    "\n",
    "df['CleanedTweet'] = df['OriginalTweet'].apply(clean_tweet)\n",
    "\n",
    "print(df['CleanedTweet'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.**\n",
    "\n",
    "Токенизируйте тексты твитов с помощью `word_tokenize()` из библиотеки `nltk`. Лемматизируйте с помощью `WordNetLemmatizer()` из той же библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ИВАН\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "# Инициализация токенизатора\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Инициализация лемматизатора\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "df['LemmatizedTweet'] = df['CleanedTweet'].apply(lambda x: ' '.join([lemmatizer.lemmatize(token) for token in tokenizer.tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.**\n",
    "\n",
    "Разделите данные на обучающую и тестовую выборку (используем только обработанные тексты твитов из прошлого задания и разметку) в соотношении 70 на 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборку\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Сохранение разметки в отдельные переменные\n",
    "train_labels = train_data['Sentiment']\n",
    "test_labels = test_data['Sentiment']\n",
    "\n",
    "# Сохранение обработанных текстов твитов в отдельные переменные\n",
    "train_texts = train_data['LemmatizedTweet']\n",
    "test_texts = test_data['LemmatizedTweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.**\n",
    "\n",
    "Примените `CountVectorizer()`, не забудьте убрать стоп-слова с помощью аргумента `stop_words='english'`. Обучите логистическую регрессию. Выведите `classification_report` из библиотеки `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.80      0.80      4577\n",
      "     Neutral       0.70      0.75      0.73      2292\n",
      "    Positive       0.84      0.83      0.84      5479\n",
      "\n",
      "    accuracy                           0.80     12348\n",
      "   macro avg       0.79      0.79      0.79     12348\n",
      "weighted avg       0.81      0.80      0.80     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Обработка данных и создание объекта CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_counts = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_counts, train_labels)\n",
    "\n",
    "# Применение модели к тестовым данным\n",
    "X_test_counts = vectorizer.transform(test_texts)\n",
    "y_pred = model.predict(X_test_counts)\n",
    "\n",
    "# Оценка модели\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.**\n",
    "\n",
    "Подберите параметры `C` и `penalty` для логистической регрессии так, чтобы получилось улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация данных...\n",
      "Размерность признаков: 5000\n",
      "Векторизация заняла: 0.8 секунд\n",
      "\n",
      "Проверяем C=0.001, penalty=l1\n",
      "F1-score: 0.2727\n",
      "\n",
      "Проверяем C=0.001, penalty=l2\n",
      "F1-score: 0.5980\n",
      "\n",
      "Проверяем C=0.01, penalty=l1\n",
      "F1-score: 0.5544\n",
      "\n",
      "Проверяем C=0.01, penalty=l2\n",
      "F1-score: 0.6922\n",
      "\n",
      "Проверяем C=0.1, penalty=l1\n",
      "F1-score: 0.7331\n",
      "\n",
      "Проверяем C=0.1, penalty=l2\n",
      "F1-score: 0.7724\n",
      "\n",
      "Проверяем C=1, penalty=l1\n",
      "F1-score: 0.8149\n",
      "\n",
      "Проверяем C=1, penalty=l2\n",
      "F1-score: 0.8016\n",
      "\n",
      "Проверяем C=10, penalty=l1\n",
      "F1-score: 0.7804\n",
      "\n",
      "Проверяем C=10, penalty=l2\n",
      "F1-score: 0.7865\n",
      "\n",
      "Проверяем C=100, penalty=l1\n",
      "F1-score: 0.7656\n",
      "\n",
      "Проверяем C=100, penalty=l2\n",
      "F1-score: 0.7707\n",
      "\n",
      "Проверяем C=1000, penalty=l1\n",
      "F1-score: 0.7636\n",
      "\n",
      "Проверяем C=1000, penalty=l2\n",
      "F1-score: 0.7642\n",
      "\n",
      "==================================================\n",
      "Общее время: 20.2 секунд\n",
      "Лучшие параметры: {'C': 1, 'penalty': 'l1'}\n",
      "Лучший F1-score: 0.8149\n",
      "==================================================\n",
      "\n",
      "Детальный отчет лучшей модели:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.79      0.81      4577\n",
      "     Neutral       0.67      0.83      0.74      2292\n",
      "    Positive       0.87      0.82      0.85      5479\n",
      "\n",
      "    accuracy                           0.81     12348\n",
      "   macro avg       0.79      0.82      0.80     12348\n",
      "weighted avg       0.82      0.81      0.81     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Векторизуем один раз для всех моделей\n",
    "print(\"Векторизация данных...\")\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "print(f\"Размерность признаков: {X_train.shape[1]}\")\n",
    "print(f\"Векторизация заняла: {time.time() - start_time:.1f} секунд\")\n",
    "\n",
    "# Параметры для перебора\n",
    "C_values = [ 1e-3, 1e-2, 0.1, 1, 10, 100, 1000]\n",
    "penalty_options = ['l1', 'l2']\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "# Теперь быстро обучаем модели\n",
    "for C in C_values:\n",
    "    for penalty in penalty_options:\n",
    "        print(f\"\\nПроверяем C={C}, penalty={penalty}\")\n",
    "        \n",
    "        # Создаем и обучаем модель\n",
    "        model = LogisticRegression(\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            solver='liblinear',\n",
    "            max_iter=300,  # уменьшаем для скорости\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            l1_ratio=0.5 if penalty == 'elasticnet' else None\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, train_labels)\n",
    "        \n",
    "        # Оценка\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(test_labels, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"F1-score: {score:.4f}\")\n",
    "        \n",
    "        # Сохраняем лучшую модель\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = {'C': C, 'penalty': penalty}\n",
    "            best_model = model\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Общее время: {time.time() - start_time:.1f} секунд\")\n",
    "print(f\"Лучшие параметры: {best_params}\")\n",
    "print(f\"Лучший F1-score: {best_score:.4f}\")\n",
    "print('='*50)\n",
    "\n",
    "print(\"\\nДетальный отчет лучшей модели:\")\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(classification_report(test_labels, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8.**\n",
    "\n",
    "Попробуйте разные значения `ngram_range`. Как меняется результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(1, 1)\n",
      "============================================================\n",
      "F1-score: 0.8240 (+/- 0.0020)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(1, 2)\n",
      "============================================================\n",
      "F1-score: 0.7878 (+/- 0.0005)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(1, 3)\n",
      "============================================================\n",
      "F1-score: 0.7833 (+/- 0.0005)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(2, 2)\n",
      "============================================================\n",
      "F1-score: 0.5835 (+/- 0.0014)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(2, 3)\n",
      "============================================================\n",
      "F1-score: 0.5773 (+/- 0.0020)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(3, 3)\n",
      "============================================================\n",
      "F1-score: 0.4497 (+/- 0.0021)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "ИТОГИ:\n",
      "============================================================\n",
      "1. ngram_range=(1, 1): F1 = 0.8240 (+/- 0.0020)\n",
      "2. ngram_range=(1, 2): F1 = 0.7878 (+/- 0.0005)\n",
      "3. ngram_range=(1, 3): F1 = 0.7833 (+/- 0.0005)\n",
      "4. ngram_range=(2, 2): F1 = 0.5835 (+/- 0.0014)\n",
      "5. ngram_range=(2, 3): F1 = 0.5773 (+/- 0.0020)\n",
      "6. ngram_range=(3, 3): F1 = 0.4497 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Список разных диапазонов n-грамм для тестирования\n",
    "ngram_ranges = [\n",
    "    (1, 1),  # только униграммы (отдельные слова)\n",
    "    (1, 2),  # униграммы + биграммы\n",
    "    (1, 3),  # униграммы + биграммы + триграммы\n",
    "    (2, 2),  # только биграммы\n",
    "    (2, 3),  # биграммы + триграммы\n",
    "    (3, 3),  # только триграммы\n",
    "]\n",
    "\n",
    "# Будем сохранять результаты\n",
    "results = []\n",
    "\n",
    "# Фиксируем оптимальные параметры из предыдущего поиска\n",
    "best_C = best_params['C']\n",
    "best_penalty = best_params['penalty']\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Тестируем ngram_range={ngram_range}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Создаем новый пайплайн с текущим ngram_range\n",
    "    pipeline = Pipeline([\n",
    "        ('vct', CountVectorizer(\n",
    "            stop_words='english',\n",
    "            ngram_range=ngram_range,\n",
    "            max_features=5000  # Ограничим для скорости\n",
    "        )),\n",
    "        ('clf', LogisticRegression(\n",
    "            C=best_C,\n",
    "            penalty=best_penalty,\n",
    "            solver='liblinear',\n",
    "            max_iter=500,\n",
    "            random_state=42,\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    scores = cross_val_score(\n",
    "        pipeline,\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        cv=3,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    results.append((ngram_range, mean_score, std_score))\n",
    "    \n",
    "    print(f\"F1-score: {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "    \n",
    "    # Также посмотрим на размерность признаков\n",
    "    pipeline.fit(train_texts[:1000], train_labels[:1000])  # на части данных\n",
    "    n_features = len(pipeline.named_steps['vct'].get_feature_names_out())\n",
    "    print(f\"Количество признаков: {n_features}\")\n",
    "\n",
    "# Сортируем результаты по F1-score\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ИТОГИ:\")\n",
    "print('='*60)\n",
    "for i, (ngram_range, mean_score, std_score) in enumerate(results, 1):\n",
    "    print(f\"{i}. ngram_range={ngram_range}: F1 = {mean_score:.4f} (+/- {std_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9.**\n",
    "\n",
    "Теперь воспользуемся `TfidfVectorizer`. Повторите задания 6-7-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.81      0.80      4577\n",
      "     Neutral       0.74      0.59      0.66      2292\n",
      "    Positive       0.80      0.85      0.83      5479\n",
      "\n",
      "    accuracy                           0.79     12348\n",
      "   macro avg       0.78      0.75      0.76     12348\n",
      "weighted avg       0.79      0.79      0.78     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Обработка данных и создание объекта CountVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_counts = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_counts, train_labels)\n",
    "\n",
    "# Применение модели к тестовым данным\n",
    "X_test_counts = vectorizer.transform(test_texts)\n",
    "y_pred = model.predict(X_test_counts)\n",
    "\n",
    "# Оценка модели\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность признаков: 5000\n",
      "Векторизация заняла: 0.8 секунд\n",
      "\n",
      "Проверяем C=0.001, penalty=l1\n",
      "F1-score: 0.2727\n",
      "\n",
      "Проверяем C=0.001, penalty=l2\n",
      "F1-score: 0.2984\n",
      "\n",
      "Проверяем C=0.01, penalty=l1\n",
      "F1-score: 0.3547\n",
      "\n",
      "Проверяем C=0.01, penalty=l2\n",
      "F1-score: 0.5573\n",
      "\n",
      "Проверяем C=0.1, penalty=l1\n",
      "F1-score: 0.6428\n",
      "\n",
      "Проверяем C=0.1, penalty=l2\n",
      "F1-score: 0.7121\n",
      "\n",
      "Проверяем C=1, penalty=l1\n",
      "F1-score: 0.8110\n",
      "\n",
      "Проверяем C=1, penalty=l2\n",
      "F1-score: 0.7826\n",
      "\n",
      "Проверяем C=10, penalty=l1\n",
      "F1-score: 0.7970\n",
      "\n",
      "Проверяем C=10, penalty=l2\n",
      "F1-score: 0.7998\n",
      "\n",
      "Проверяем C=100, penalty=l1\n",
      "F1-score: 0.7721\n",
      "\n",
      "Проверяем C=100, penalty=l2\n",
      "F1-score: 0.7849\n",
      "\n",
      "Проверяем C=1000, penalty=l1\n",
      "F1-score: 0.7681\n",
      "\n",
      "Проверяем C=1000, penalty=l2\n",
      "F1-score: 0.7729\n",
      "\n",
      "==================================================\n",
      "Общее время: 11.1 секунд\n",
      "Лучшие параметры: {'C': 1, 'penalty': 'l1'}\n",
      "Лучший F1-score: 0.8110\n",
      "==================================================\n",
      "\n",
      "Детальный отчет лучшей модели:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.78      0.81      4577\n",
      "     Neutral       0.65      0.87      0.74      2292\n",
      "    Positive       0.87      0.81      0.84      5479\n",
      "\n",
      "    accuracy                           0.81     12348\n",
      "   macro avg       0.79      0.82      0.80     12348\n",
      "weighted avg       0.82      0.81      0.81     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "print(f\"Размерность признаков: {X_train.shape[1]}\")\n",
    "print(f\"Векторизация заняла: {time.time() - start_time:.1f} секунд\")\n",
    "\n",
    "# Параметры для перебора\n",
    "C_values = [ 1e-3, 1e-2, 0.1, 1, 10, 100, 1000]\n",
    "penalty_options = ['l1', 'l2']\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "# Теперь быстро обучаем модели\n",
    "for C in C_values:\n",
    "    for penalty in penalty_options:\n",
    "        print(f\"\\nПроверяем C={C}, penalty={penalty}\")\n",
    "        \n",
    "        # Создаем и обучаем модель\n",
    "        model = LogisticRegression(\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            solver='liblinear',\n",
    "            max_iter=300,  # уменьшаем для скорости\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            l1_ratio=0.5 if penalty == 'elasticnet' else None\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, train_labels)\n",
    "        \n",
    "        # Оценка\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(test_labels, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"F1-score: {score:.4f}\")\n",
    "        \n",
    "        # Сохраняем лучшую модель\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = {'C': C, 'penalty': penalty}\n",
    "            best_model = model\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Общее время: {time.time() - start_time:.1f} секунд\")\n",
    "print(f\"Лучшие параметры: {best_params}\")\n",
    "print(f\"Лучший F1-score: {best_score:.4f}\")\n",
    "print('='*50)\n",
    "\n",
    "print(\"\\nДетальный отчет лучшей модели:\")\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(classification_report(test_labels, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(1, 1)\n",
      "============================================================\n",
      "F1-score: 0.7974 (+/- 0.0018)\n",
      "Количество признаков: 4826\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(1, 2)\n",
      "============================================================\n",
      "F1-score: 0.7942 (+/- 0.0030)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(1, 3)\n",
      "============================================================\n",
      "F1-score: 0.7933 (+/- 0.0031)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(2, 2)\n",
      "============================================================\n",
      "F1-score: 0.4879 (+/- 0.0010)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(2, 3)\n",
      "============================================================\n",
      "F1-score: 0.4871 (+/- 0.0029)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "Тестируем ngram_range=(3, 3)\n",
      "============================================================\n",
      "F1-score: 0.3607 (+/- 0.0016)\n",
      "Количество признаков: 5000\n",
      "\n",
      "============================================================\n",
      "ИТОГИ:\n",
      "============================================================\n",
      "1. ngram_range=(1, 1): F1 = 0.7974 (+/- 0.0018)\n",
      "2. ngram_range=(1, 2): F1 = 0.7942 (+/- 0.0030)\n",
      "3. ngram_range=(1, 3): F1 = 0.7933 (+/- 0.0031)\n",
      "4. ngram_range=(2, 2): F1 = 0.4879 (+/- 0.0010)\n",
      "5. ngram_range=(2, 3): F1 = 0.4871 (+/- 0.0029)\n",
      "6. ngram_range=(3, 3): F1 = 0.3607 (+/- 0.0016)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Список разных диапазонов n-грамм для тестирования\n",
    "ngram_ranges = [\n",
    "    (1, 1),  # только униграммы (отдельные слова)\n",
    "    (1, 2),  # униграммы + биграммы\n",
    "    (1, 3),  # униграммы + биграммы + триграммы\n",
    "    (2, 2),  # только биграммы\n",
    "    (2, 3),  # биграммы + триграммы\n",
    "    (3, 3),  # только триграммы\n",
    "]\n",
    "\n",
    "# Будем сохранять результаты\n",
    "results = []\n",
    "\n",
    "# Фиксируем оптимальные параметры из предыдущего поиска\n",
    "best_C = best_params['C']\n",
    "best_penalty = best_params['penalty']\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Тестируем ngram_range={ngram_range}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Создаем новый пайплайн с текущим ngram_range\n",
    "    pipeline = Pipeline([\n",
    "        ('vct', TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            ngram_range=ngram_range,\n",
    "            max_features=5000  # Ограничим для скорости\n",
    "        )),\n",
    "        ('clf', LogisticRegression(\n",
    "            C=best_C,\n",
    "            penalty=best_penalty,\n",
    "            solver='liblinear',\n",
    "            max_iter=500,\n",
    "            random_state=42,\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    scores = cross_val_score(\n",
    "        pipeline,\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        cv=3,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    results.append((ngram_range, mean_score, std_score))\n",
    "    \n",
    "    print(f\"F1-score: {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "    \n",
    "    # Также посмотрим на размерность признаков\n",
    "    pipeline.fit(train_texts[:1000], train_labels[:1000])  # на части данных\n",
    "    n_features = len(pipeline.named_steps['vct'].get_feature_names_out())\n",
    "    print(f\"Количество признаков: {n_features}\")\n",
    "\n",
    "# Сортируем результаты по F1-score\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ИТОГИ:\")\n",
    "print('='*60)\n",
    "for i, (ngram_range, mean_score, std_score) in enumerate(results, 1):\n",
    "    print(f\"{i}. ngram_range={ngram_range}: F1 = {mean_score:.4f} (+/- {std_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10.**\n",
    "\n",
    "В этом и последующих заданиях будем пользоваться векторами, полученными с помощью `TfidfVectorizer`. Обучите модель случайного леса, подобрав параметры `n_estimators`, `max_depth` с помощью GridSearch c 5 фолдами и параметром `scoring = 'accuracy'`. Выведите `classification_report` для лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ GRIDSEARCH:\n",
      "============================================================\n",
      "Лучшие параметры: {'max_depth': 20, 'n_estimators': 200}\n",
      "Лучшая accuracy: 0.6051\n",
      "Лучший estimator: RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=200,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "\n",
      "============================================================\n",
      "ОЦЕНКА НА ТЕСТОВОЙ ВЫБОРКЕ:\n",
      "============================================================\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.53      0.61      4577\n",
      "     Neutral       0.37      0.84      0.51      2292\n",
      "    Positive       0.81      0.55      0.65      5479\n",
      "\n",
      "    accuracy                           0.60     12348\n",
      "   macro avg       0.63      0.64      0.59     12348\n",
      "weighted avg       0.69      0.60      0.61     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # ← ВМЕСТО 5000! (в 5 раз быстрее)\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_texts)\n",
    "X_test_tfidf = tfidf.transform(test_texts)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # используем все ядра\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # количество деревьев\n",
    "    'max_depth': [10, 20],  # глубина деревьев\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-фолдовая кросс-валидация\n",
    "    scoring='accuracy',  # метрика - accuracy\n",
    "    n_jobs=-1,  # параллельные вычисления\n",
    "    verbose=2,  # вывод прогресса\n",
    "    return_train_score=True\n",
    ")\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# 6. Выводим результаты\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ GRIDSEARCH:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "print(f\"Лучшая accuracy: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Лучший estimator: {grid_search.best_estimator_}\")\n",
    "\n",
    "# 7. Оцениваем на тестовой выборке\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ОЦЕНКА НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 11.**\n",
    "\n",
    "Обучите модель `SGDClassifier`, подобрав параметры `alpha` и `penalty` с помощью GridSearch c 5 фолдами и параметром `scoring = 'accuracy'`. Выведите `classification_report` для лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск GridSearchCV с пайплайном...\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ:\n",
      "============================================================\n",
      "Лучшие параметры: {'alpha': 1e-05, 'penalty': 'l1'}\n",
      "Лучшая accuracy: 0.7374\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT НА ТЕСТЕ:\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.67      0.73      4577\n",
      "     Neutral       0.53      0.86      0.65      2292\n",
      "    Positive       0.84      0.74      0.79      5479\n",
      "\n",
      "    accuracy                           0.73     12348\n",
      "   macro avg       0.72      0.75      0.72     12348\n",
      "weighted avg       0.77      0.73      0.74     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "sgd = SGDClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    sgd,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"Запуск GridSearchCV с пайплайном...\")\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Результаты\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "print(f\"Лучшая accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT НА ТЕСТЕ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tfidf)\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 12.**\n",
    "\n",
    "Обучите модель XGBoost, подобрав параметры `max_depth`, `n_estimators` и `learning_rate` с помощью GridSearch c 5 фолдами и параметром `scoring = 'accuracy'`. Выведите `classification_report` для лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соответствие меток:\n",
      "Negative -> 0\n",
      "Neutral -> 1\n",
      "Positive -> 2\n",
      "Запуск GridSearchCV для XGBoost...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ:\n",
      "============================================================\n",
      "Лучшие параметры: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 100}\n",
      "Лучшая accuracy: 0.7240\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT НА ТЕСТЕ:\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.68      0.72      4577\n",
      "     Neutral       0.57      0.70      0.63      2292\n",
      "    Positive       0.78      0.76      0.77      5479\n",
      "\n",
      "    accuracy                           0.72     12348\n",
      "   macro avg       0.70      0.72      0.70     12348\n",
      "weighted avg       0.73      0.72      0.72     12348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1. Преобразуем строковые метки в числовые\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(train_labels)\n",
    "y_test_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Проверяем соответствие\n",
    "print(\"Соответствие меток:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label} -> {i}\")\n",
    "\n",
    "# 2. Создаем модель XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 3. Определяем сетку параметров\n",
    "param_grid = {\n",
    "    'max_depth': [3, 7],  # глубина деревьев\n",
    "    'n_estimators': [50, 100],  # количество деревьев\n",
    "    'learning_rate': [0.01, 0.3],  # скорость обучения\n",
    "}\n",
    "\n",
    "# 4. Создаем GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    xgb,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"Запуск GridSearchCV для XGBoost...\")\n",
    "grid_search.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# 5. Выводим результаты\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "print(f\"Лучшая accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 6. Оценка на тестовой выборке\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT НА ТЕСТЕ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_encoded = grid_search.predict(X_test_tfidf)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
